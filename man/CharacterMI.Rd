% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dataset_information.R
\name{CharacterMI}
\alias{CharacterMI}
\alias{CharacterEntropy}
\alias{CharacterEntropies}
\alias{ApportionAmbiguity}
\alias{JointCharacterEntropy}
\alias{JointCharacterEntropies}
\alias{MutualCharacterInformation}
\alias{MutCharInfo}
\title{Mutual information between characters}
\usage{
CharacterEntropy(char, ignore = character(0))

CharacterEntropies(chars, ignore = character(0))

ApportionAmbiguity(char, ignore = character(0))

JointCharacterEntropy(
  char1,
  char2,
  ignore = character(0),
  ignore1 = NULL,
  ignore2 = NULL,
  states1 = NULL,
  states2 = NULL,
  tokens1 = NULL,
  tokens2 = NULL
)

JointCharacterEntropies(characters, ignore = character(0))

MutualCharacterInformation(characters, ignore = character(0))

MutCharInfo(characters, ignore = character(0))
}
\arguments{
\item{char, char1, char2}{Character vector listing character tokens.
For handling of ambiguous tokens, see section 'Ambiguity'.}

\item{ignore}{Character vector listing tokens to treat as ambiguous,
besides \verb{?} and \code{-}.}
}
\description{
Calculate the entropy, joint entropy and mutual information between
characters in a morphological dataset,
distinguishing 'background' mutual information due to
shared ancestry and random chance from functionally significant correlations.
}
\details{
\code{CharacterEntropy()} and \code{CharacterEntropies()} calculate the entropy of
individual characters, using \code{ApportionAmiguity()} to assign frequencies
to ambiguous tokens.

\code{JointCharacterEntropy()} and \code{JointCharacterEntropies()} calculate the
joint entropy of pairs of characters.

\code{MutualCharacterInformation()} calculates the mutual information between
each pair of characters: i.e. the extent to which the state of one character
can be guessed based on the state of the other.

The mutual information (MI) of two characters is assumed to represent the
contribution of two components: background MI (\emph{MIb}), comprising
a signal from shared ancestry overprinted with random noise, and
MI arising from structure and function (\emph{MSsf}).
Dunn \emph{et al.} (2008) use this
measure to identify amino acids that play a role in the structure or
function of proteins -- mutations in one AA will require compensatory
mutations in other AA if the protein is to continue functioning.
A morphological analogy is proposed.

The average product correlation (APC), the product of the average MI of
each character with  each other character in the dataset), approximates
the background mutual information.
A high mean value of MIb across a dataset implies that there is a strong
phylogenetic signal.

\emph{MIp}, the difference between the mutual information of two characters
and their APC, approximates \emph{MIsf}.

The runtime increases with the square of the number of characters --
may take a couple of seconds to calculate with 100 characters.
}
\section{Ambiguity}{

Ambiguous characters should be specified as a string containing all possible
characters states (and, optionally, parentheses): e.g. \verb{[01]}.
\verb{?} and \code{-} will be interpreted as 'any possible value'.
Each token is assigned a probability according to its number of
\emph{non-ambiguous} occurrences in the character.
Example: in \verb{000000 1111 [01] [02] ?}, \verb{[01]} and \verb{?} will be taken to have
a 6/10 chance of being token \code{0};
\verb{[02]} will be treated as having a 100\% chance of being state \code{0}.
}

\examples{
data('Lobo', package = 'TreeTools')
dat <- PhyDatToMatrix(Lobo.phy)[, 1:6]

CharacterEntropies(dat)
apply(dat, 2, CharacterEntropy)
JointCharacterEntropies(dat)
MutualCharacterInformation(dat)

h1 <- JointCharacterEntropies(dat)
fit <- cmdscale(h1, k=2)
plot(fit, type = 'n')
text(fit[, 1], fit[, 2], 1:196, cex = 0.8)
char <- c(rep('0', 6), rep('1', 4), '[01]', '[02]', '?')
ShareAmbiguity(char)
ShareAmbiguity(char, ignore = '[02]')
CharacterEntropy(char)
}
\references{
\insertRef{Dunn2008}{TreeTools}
}
\author{
\href{https://orcid.org/0000-0001-5660-1727}{Martin R. Smith}
(\href{mailto:martin.smith@durham.ac.uk}{martin.smith@durham.ac.uk})
}
